{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da2d5fa5-502a-4d75-9865-2b2c35f7b8a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97de3b62-a620-400d-92bf-9316c099d508",
   "metadata": {},
   "source": [
    "This file requires three inputs: result and ground truth csv files as well as the prompt file. Samples of all files are included inside 'data' folder.\n",
    "\n",
    "This file:\n",
    "1. Generates comparisons of result and ground truth values and calculates accuracy paper-wise (row-wise) and sub-criteria-wise (column wise).\n",
    "2. Calculates two tables based on per-sub-criteria values: per-paper metrics and per-sub-criteria metrics.\n",
    "3. Calculates risk-level per criteria.\n",
    "4. Generates comparisons of result and ground truth risk-level per criteria values and calculates accuracy paper-wise (row-wise) and risk-level per criteria-wise (column wise).\n",
    "5. Calculates metrics for risk-level per-criteria (confusion matrix).\n",
    "6. Save all results (separated into multiple sheets) into an excel file.\n",
    "\n",
    "Make sure the paper_id (paper title) column is the same and alphabetically increasing ordered for both ground truth and LLM results. The order and number of the criteria columns need to be similar aswell for both ground truth and LLM results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd43eea-2418-4727-8517-4b2c5b5ef601",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f3d4bc9-d64c-4279-a1fe-8ca75f5bff1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Input files.\n",
    "# =========================\n",
    "LLM_CSV_PATH = \"data/llm_train.csv\"     # LLM results\n",
    "GT_CSV_PATH  = \"data/lsr_train.csv\"    # ground truth\n",
    "PROMPT_PATH = \"data/prompt.yaml\" # prompt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3799d684-a000-4a08-a429-49725d537036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Config Continued\n",
    "# =========================\n",
    "\n",
    "# Column in BOTH CSVs that contains the paper identifier (first column by position).\n",
    "PAPER_ID_COL = \"paper_id\"\n",
    "\n",
    "# Predefined SUB_CRITERIA.\n",
    "# SUB_CRITERIA = [\n",
    "#     \"criteria 1.1\", \"criteria 1.2\", \"criteria 1.3\", \"criteria 1.4\", \"criteria 1.5\",\n",
    "#     \"criteria 2.1\", \"criteria 2.3\", \"criteria 2.4\", \"criteria 2.5\", \"criteria 2.6\",\n",
    "#     \"criteria 5.1\",\n",
    "#     \"criteria 6.1\", \"criteria 6.2\", \"criteria 6.3\",\n",
    "#     \"criteria 7.1\", \"criteria 7.2\", \"criteria 7.3\", \"criteria 7.4\",\n",
    "# ]\n",
    "\n",
    "# Generated SUB_CRITERIA from prompt.yaml.\n",
    "with open(PROMPT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    doc = yaml.safe_load(f) or {}\n",
    "\n",
    "nested_subs = {\n",
    "    crit[\"id\"]: {\n",
    "        sub[\"id\"]: {\n",
    "            \"title\": sub.get(\"title\", \"\"),\n",
    "            \"instruction\": sub.get(\"instruction\", \"\")\n",
    "        }\n",
    "        for sub in crit.get(\"sub_criteria\", [])\n",
    "    }\n",
    "    for crit in doc.get(\"Criteria\", [])\n",
    "}\n",
    "\n",
    "SUB_CRITERIA = []\n",
    "for criteria_id, sub_crit_dict in nested_subs.items():\n",
    "    for sub_crit_id, sub_crit in sub_crit_dict.items():\n",
    "        SUB_CRITERIA.append(f\"criteria {sub_crit_id}\")\n",
    "\n",
    "# Presentation\n",
    "DISPLAY_SEPARATOR = \" / \"  # string between LLM and GT values in a cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53390cc-b997-4c6c-b38d-74946deae828",
   "metadata": {
    "tags": []
   },
   "source": [
    "This script will take the PAPER_IDS and CRITERIA from either one dataframe (either ground truth or LLM results) and apply it to the other dataframe. \n",
    "Hence, naming isn't important here, but ordering of the paper and criteria will be important. Ordering has to be the same between both dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a05b94-daf3-42ec-93fe-7191c16003b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Result Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "021948bd-1285-450b-8496-3a09cbf57451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Imports & helpers\n",
    "# =========================\n",
    "\n",
    "def _canon_label(x: object) -> str:\n",
    "    \"\"\"Converts all into lowercase; map 'probably yes/no' to 'yes/no'; empty for NaN.\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    s = str(x).strip().lower()\n",
    "    if s == \"probably yes\":\n",
    "        s = \"yes\"\n",
    "    elif s == \"probably no\":\n",
    "        s = \"no\"\n",
    "    return s\n",
    "\n",
    "def _clean_col(s: str) -> str:\n",
    "    \"\"\"Simple normalization for column names (used in string mode).\"\"\"\n",
    "    return \" \".join(str(s).strip().lower().split())\n",
    "\n",
    "def load_by_position(dataframe: pd.DataFrame, paper_ids: list[str], criteria: list[str], paper_id_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read CSV assuming:\n",
    "    - First column (by position) is the paper id, and rows appear in the same order as PAPER_IDS\n",
    "    - Next len(criteria) columns (by position) correspond to CRITERIA in that exact order\n",
    "    Any extra columns after criteria are ignored. Column *names* in the file don't matter.\n",
    "    \"\"\"\n",
    "    df = dataframe\n",
    "    need_cols = 1 + len(criteria)\n",
    "    if df.shape[1] < need_cols:\n",
    "        raise ValueError(f\"Dataframe: expected at least {need_cols} columns (id + {len(criteria)} criteria), got {df.shape[1]}.\")\n",
    "\n",
    "    df = df.iloc[:, :need_cols]\n",
    "\n",
    "    # Rename columns (first col -> PAPER_ID_COL, rest -> CRITERIA).\n",
    "    df.columns = [paper_id_col] + criteria\n",
    "\n",
    "    # Enforce row count/order by position\n",
    "    if df.shape[0] != len(paper_ids):\n",
    "        raise ValueError(f\"Dataframe: expected exactly {len(paper_ids)} rows (one per paper), got {df.shape[0]}.\")\n",
    "\n",
    "    df[paper_id_col] = paper_ids\n",
    "    df = df.set_index(paper_id_col)\n",
    "\n",
    "    # Canonicalize labels\n",
    "    for c in criteria:\n",
    "        df[c] = df[c].apply(_canon_label)\n",
    "\n",
    "    return df\n",
    "\n",
    "def build_comparison(llm_df: pd.DataFrame, gt_df: pd.DataFrame, paper_ids: list[str], criteria: list[str], sep: str) -> pd.DataFrame:\n",
    "    \"\"\"Return a criteria × papers table with 'llm / ground truth' strings.\"\"\"\n",
    "    out = pd.DataFrame(index=criteria, columns=paper_ids, dtype=object)\n",
    "    for p in paper_ids:\n",
    "        for c in criteria:\n",
    "            pred  = \"\" if pd.isna(llm_df.loc[p, c]) else str(llm_df.loc[p, c])\n",
    "            truth = \"\" if pd.isna(gt_df.loc[p, c])  else str(gt_df.loc[p, c])\n",
    "            out.at[c, p] = f\"{pred}{sep}{truth}\"\n",
    "            \n",
    "    # Overall Accuracy:\n",
    "    acc_per_paper_list = []\n",
    "    for p in paper_ids:\n",
    "        for c in criteria:\n",
    "            acc_per_paper_list.append(str(llm_df.loc[p, c]) == str(gt_df.loc[p, c]))\n",
    "            \n",
    "    return out, np.mean(acc_per_paper_list).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aac1ad63-9b33-45ca-9d0d-9ff32db3e6f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Import Data & Wrangle\n",
    "# =========================\n",
    "df_llm_raw = pd.read_csv(LLM_CSV_PATH)\n",
    "df_gt_raw = pd.read_csv(GT_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6359d6c3-3ce9-4763-ad51-9ceb3cf4d7ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>file_name</th>\n",
       "      <th>1.1) Confounder Possibility</th>\n",
       "      <th>1.2) Confounder All</th>\n",
       "      <th>1.3) Confounder Justified Omission</th>\n",
       "      <th>1.4) Confounder Accuracy</th>\n",
       "      <th>1.5) Confounder Analysis</th>\n",
       "      <th>2.1) SampleExchangeability</th>\n",
       "      <th>2.3) Sample Exclusion</th>\n",
       "      <th>2.4) SampleGroupComparability</th>\n",
       "      <th>2.5) Sample Group Difference Intervention</th>\n",
       "      <th>2.6) Sample Bias Adjustment</th>\n",
       "      <th>5.1) Aware of Study</th>\n",
       "      <th>6.1) DataSelective</th>\n",
       "      <th>6.2) Data_Subgroups</th>\n",
       "      <th>6.3) Data_Causal</th>\n",
       "      <th>7.1) StatsRecording</th>\n",
       "      <th>7.2) Stats_Descriptive_Error</th>\n",
       "      <th>7.3) Stats_Inferential_Error</th>\n",
       "      <th>7.4) Stats_Inferential_Violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Allcott, H (2011).md</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ayres, Raseman, Shih, 2012.md</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bager, S; Mundaca, L (2017).md</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Carroll, J; Lyons, S; Denny, E (2014).md</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Houde, S; Todd, A; Sudarshan, A; Flora, JA; Ar...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no                                          file_name  \\\n",
       "0   1                               Allcott, H (2011).md   \n",
       "1   2                      Ayres, Raseman, Shih, 2012.md   \n",
       "2   3                     Bager, S; Mundaca, L (2017).md   \n",
       "3   4           Carroll, J; Lyons, S; Denny, E (2014).md   \n",
       "4   5  Houde, S; Todd, A; Sudarshan, A; Flora, JA; Ar...   \n",
       "\n",
       "  1.1) Confounder Possibility 1.2) Confounder All  \\\n",
       "0                          no                 yes   \n",
       "1                         yes                 yes   \n",
       "2                         yes                  no   \n",
       "3                         yes                  no   \n",
       "4                         yes                 yes   \n",
       "\n",
       "  1.3) Confounder Justified Omission 1.4) Confounder Accuracy  \\\n",
       "0                                 no                       no   \n",
       "1                                 no                      yes   \n",
       "2                                 no                      yes   \n",
       "3                                 no                      yes   \n",
       "4                                 no                       no   \n",
       "\n",
       "  1.5) Confounder Analysis 2.1) SampleExchangeability 2.3) Sample Exclusion  \\\n",
       "0                      yes                        yes                   yes   \n",
       "1                      yes                        yes                   yes   \n",
       "2                      yes                        yes                   yes   \n",
       "3                      yes                        yes                   yes   \n",
       "4                      yes                        yes                   yes   \n",
       "\n",
       "  2.4) SampleGroupComparability 2.5) Sample Group Difference Intervention  \\\n",
       "0                           yes                                       yes   \n",
       "1                            no                                       yes   \n",
       "2                           yes                                       yes   \n",
       "3                           yes                                       yes   \n",
       "4                           yes                                       yes   \n",
       "\n",
       "  2.6) Sample Bias Adjustment 5.1) Aware of Study 6.1) DataSelective  \\\n",
       "0                         yes                 yes                yes   \n",
       "1                         yes                 yes                yes   \n",
       "2                         yes                 yes                yes   \n",
       "3                         yes                 yes                yes   \n",
       "4                         yes                 yes                yes   \n",
       "\n",
       "  6.2) Data_Subgroups 6.3) Data_Causal 7.1) StatsRecording  \\\n",
       "0                 yes              yes                 yes   \n",
       "1                  no              yes                 yes   \n",
       "2                  no              yes                 yes   \n",
       "3                  no              yes                 yes   \n",
       "4                  no              yes                 yes   \n",
       "\n",
       "  7.2) Stats_Descriptive_Error 7.3) Stats_Inferential_Error  \\\n",
       "0                           no                          yes   \n",
       "1                          yes                           no   \n",
       "2                          yes                          yes   \n",
       "3                          yes                          yes   \n",
       "4                          yes                          yes   \n",
       "\n",
       "  7.4) Stats_Inferential_Violation  \n",
       "0                               no  \n",
       "1                               no  \n",
       "2                              yes  \n",
       "3                               no  \n",
       "4                               no  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unformatted LLM results.\n",
    "df_llm_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f08dd806-364b-49eb-9370-1578b627e619",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>effectID</th>\n",
       "      <th>coder</th>\n",
       "      <th>Authors</th>\n",
       "      <th>documentType</th>\n",
       "      <th>document PY</th>\n",
       "      <th>document title</th>\n",
       "      <th>data_type</th>\n",
       "      <th>abstract</th>\n",
       "      <th>StudyYear</th>\n",
       "      <th>ConfounderPossibility</th>\n",
       "      <th>...</th>\n",
       "      <th>SampleGroupDifferenceIntervention</th>\n",
       "      <th>SampleBiasAdjustment</th>\n",
       "      <th>AwareofStudy</th>\n",
       "      <th>DataSelective</th>\n",
       "      <th>DataSubgroups</th>\n",
       "      <th>DataCausal</th>\n",
       "      <th>StatsRecording</th>\n",
       "      <th>StatsDescriptiveError</th>\n",
       "      <th>StatsInferentialError</th>\n",
       "      <th>StatsInferentialViolation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23-208-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Allcott, H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011</td>\n",
       "      <td>Social norms and energy conservation</td>\n",
       "      <td>training</td>\n",
       "      <td>This paper evaluates a series of programs run ...</td>\n",
       "      <td>2011</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23-215-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ayres, I; Raseman, S; Shih, A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>Evidence from Two Large Field Experiments that...</td>\n",
       "      <td>training</td>\n",
       "      <td>By providing feedback to customers on home ele...</td>\n",
       "      <td>2013</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23-216-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bager, S; Mundaca, L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>Making 'Smart Meters' smarter? Insights from a...</td>\n",
       "      <td>training</td>\n",
       "      <td>This paper examines the relationship between l...</td>\n",
       "      <td>2017</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23-225-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carroll, J; Lyons, S; Denny, E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>Reducing household electricity demand through ...</td>\n",
       "      <td>training</td>\n",
       "      <td>The international roll out of residential smar...</td>\n",
       "      <td>2014</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23-257-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Houde, S; Todd, A; Sudarshan, A; Flora, JA; Ar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>Real-time Feedback and Electricity Consumption...</td>\n",
       "      <td>training</td>\n",
       "      <td>Real-time information feedback delivered via t...</td>\n",
       "      <td>2013</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   effectID  coder                                            Authors  \\\n",
       "0  23-208-1    NaN                                         Allcott, H   \n",
       "1  23-215-1    NaN                      Ayres, I; Raseman, S; Shih, A   \n",
       "2  23-216-1    NaN                               Bager, S; Mundaca, L   \n",
       "3  23-225-1    NaN                     Carroll, J; Lyons, S; Denny, E   \n",
       "4  23-257-1    NaN  Houde, S; Todd, A; Sudarshan, A; Flora, JA; Ar...   \n",
       "\n",
       "   documentType  document PY  \\\n",
       "0           NaN         2011   \n",
       "1           NaN         2013   \n",
       "2           NaN         2017   \n",
       "3           NaN         2014   \n",
       "4           NaN         2013   \n",
       "\n",
       "                                      document title data_type  \\\n",
       "0               Social norms and energy conservation  training   \n",
       "1  Evidence from Two Large Field Experiments that...  training   \n",
       "2  Making 'Smart Meters' smarter? Insights from a...  training   \n",
       "3  Reducing household electricity demand through ...  training   \n",
       "4  Real-time Feedback and Electricity Consumption...  training   \n",
       "\n",
       "                                            abstract  StudyYear  \\\n",
       "0  This paper evaluates a series of programs run ...       2011   \n",
       "1  By providing feedback to customers on home ele...       2013   \n",
       "2  This paper examines the relationship between l...       2017   \n",
       "3  The international roll out of residential smar...       2014   \n",
       "4  Real-time information feedback delivered via t...       2013   \n",
       "\n",
       "  ConfounderPossibility  ... SampleGroupDifferenceIntervention  \\\n",
       "0                   Yes  ...                               Yes   \n",
       "1                   Yes  ...                               Yes   \n",
       "2                   Yes  ...                               Yes   \n",
       "3                   Yes  ...                               Yes   \n",
       "4                   Yes  ...                               Yes   \n",
       "\n",
       "  SampleBiasAdjustment AwareofStudy DataSelective DataSubgroups DataCausal  \\\n",
       "0                  Yes          Yes           Yes           Yes        Yes   \n",
       "1                  Yes          Yes           Yes           Yes        Yes   \n",
       "2                  Yes          Yes           Yes           Yes        Yes   \n",
       "3                  Yes          Yes           Yes           Yes        Yes   \n",
       "4                  Yes           No           Yes           Yes        Yes   \n",
       "\n",
       "  StatsRecording StatsDescriptiveError StatsInferentialError  \\\n",
       "0            Yes                    No                    No   \n",
       "1            Yes                    No                    No   \n",
       "2            Yes                   Yes                   Yes   \n",
       "3            Yes                    No                    No   \n",
       "4            Yes                   Yes                   Yes   \n",
       "\n",
       "  StatsInferentialViolation  \n",
       "0                        No  \n",
       "1                        No  \n",
       "2                        No  \n",
       "3                        No  \n",
       "4                        No  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unformatted ground truth results.\n",
    "df_gt_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fead3845-0d47-4bf9-974d-cf8c4e8f1211",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>criteria 1.1</th>\n",
       "      <th>criteria 1.2</th>\n",
       "      <th>criteria 1.3</th>\n",
       "      <th>criteria 1.4</th>\n",
       "      <th>criteria 1.5</th>\n",
       "      <th>criteria 2.1</th>\n",
       "      <th>criteria 2.3</th>\n",
       "      <th>criteria 2.4</th>\n",
       "      <th>criteria 2.5</th>\n",
       "      <th>criteria 2.6</th>\n",
       "      <th>criteria 5.1</th>\n",
       "      <th>criteria 6.1</th>\n",
       "      <th>criteria 6.2</th>\n",
       "      <th>criteria 6.3</th>\n",
       "      <th>criteria 7.1</th>\n",
       "      <th>criteria 7.2</th>\n",
       "      <th>criteria 7.3</th>\n",
       "      <th>criteria 7.4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allcott, h</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ayres, i; raseman, s; shih, a</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bager, s; mundaca, l</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carroll, j; lyons, s; denny, e</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>houde, s; todd, a; sudarshan, a; flora, ja; ar...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            paper_id criteria 1.1  \\\n",
       "0                                         allcott, h          yes   \n",
       "1                      ayres, i; raseman, s; shih, a          yes   \n",
       "2                               bager, s; mundaca, l          yes   \n",
       "3                     carroll, j; lyons, s; denny, e          yes   \n",
       "4  houde, s; todd, a; sudarshan, a; flora, ja; ar...          yes   \n",
       "\n",
       "  criteria 1.2 criteria 1.3 criteria 1.4 criteria 1.5 criteria 2.1  \\\n",
       "0           no          yes          yes          yes          yes   \n",
       "1           no           no          yes          yes          yes   \n",
       "2           no           no          yes          yes          yes   \n",
       "3           no          yes          yes          yes          yes   \n",
       "4           no           no          yes          yes          yes   \n",
       "\n",
       "  criteria 2.3 criteria 2.4 criteria 2.5 criteria 2.6 criteria 5.1  \\\n",
       "0          yes          yes          yes          yes          yes   \n",
       "1          yes           no          yes          yes          yes   \n",
       "2          yes          yes          yes          yes          yes   \n",
       "3          yes          yes          yes          yes          yes   \n",
       "4          yes          yes          yes          yes           no   \n",
       "\n",
       "  criteria 6.1 criteria 6.2 criteria 6.3 criteria 7.1 criteria 7.2  \\\n",
       "0          yes          yes          yes          yes           no   \n",
       "1          yes          yes          yes          yes           no   \n",
       "2          yes          yes          yes          yes          yes   \n",
       "3          yes          yes          yes          yes           no   \n",
       "4          yes          yes          yes          yes          yes   \n",
       "\n",
       "  criteria 7.3 criteria 7.4  \n",
       "0           no           no  \n",
       "1           no           no  \n",
       "2          yes           no  \n",
       "3           no           no  \n",
       "4          yes           no  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrangle ground truth dataframe, drops unnecessary columns, standarizes column names.\n",
    "df_gt = df_gt_raw.drop(columns=['effectID', 'coder', 'documentType', 'document PY', 'document title', 'data_type', 'abstract', 'StudyYear'])\n",
    "df_gt.columns = [PAPER_ID_COL] + SUB_CRITERIA\n",
    "df_gt = df_gt.applymap(_canon_label)\n",
    "df_gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe332559-da56-480b-82cf-ce9ffd88e5e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['allcott, h',\n",
       " 'ayres, i; raseman, s; shih, a',\n",
       " 'bager, s; mundaca, l',\n",
       " 'carroll, j; lyons, s; denny, e',\n",
       " 'houde, s; todd, a; sudarshan, a; flora, ja; armel, kc',\n",
       " 'matsukawa, i.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take PAPER_ID_COL from one of the dataframe.\n",
    "PAPER_IDS = df_gt[PAPER_ID_COL].astype(str).tolist()\n",
    "PAPER_IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70c90b49-6e08-4dfa-b629-af5928b31908",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>criteria 1.1</th>\n",
       "      <th>criteria 1.2</th>\n",
       "      <th>criteria 1.3</th>\n",
       "      <th>criteria 1.4</th>\n",
       "      <th>criteria 1.5</th>\n",
       "      <th>criteria 2.1</th>\n",
       "      <th>criteria 2.3</th>\n",
       "      <th>criteria 2.4</th>\n",
       "      <th>criteria 2.5</th>\n",
       "      <th>criteria 2.6</th>\n",
       "      <th>criteria 5.1</th>\n",
       "      <th>criteria 6.1</th>\n",
       "      <th>criteria 6.2</th>\n",
       "      <th>criteria 6.3</th>\n",
       "      <th>criteria 7.1</th>\n",
       "      <th>criteria 7.2</th>\n",
       "      <th>criteria 7.3</th>\n",
       "      <th>criteria 7.4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allcott, h</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ayres, i; raseman, s; shih, a</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bager, s; mundaca, l</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carroll, j; lyons, s; denny, e</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>houde, s; todd, a; sudarshan, a; flora, ja; ar...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            paper_id criteria 1.1  \\\n",
       "0                                         allcott, h           no   \n",
       "1                      ayres, i; raseman, s; shih, a          yes   \n",
       "2                               bager, s; mundaca, l          yes   \n",
       "3                     carroll, j; lyons, s; denny, e          yes   \n",
       "4  houde, s; todd, a; sudarshan, a; flora, ja; ar...          yes   \n",
       "\n",
       "  criteria 1.2 criteria 1.3 criteria 1.4 criteria 1.5 criteria 2.1  \\\n",
       "0          yes           no           no          yes          yes   \n",
       "1          yes           no          yes          yes          yes   \n",
       "2           no           no          yes          yes          yes   \n",
       "3           no           no          yes          yes          yes   \n",
       "4          yes           no           no          yes          yes   \n",
       "\n",
       "  criteria 2.3 criteria 2.4 criteria 2.5 criteria 2.6 criteria 5.1  \\\n",
       "0          yes          yes          yes          yes          yes   \n",
       "1          yes           no          yes          yes          yes   \n",
       "2          yes          yes          yes          yes          yes   \n",
       "3          yes          yes          yes          yes          yes   \n",
       "4          yes          yes          yes          yes          yes   \n",
       "\n",
       "  criteria 6.1 criteria 6.2 criteria 6.3 criteria 7.1 criteria 7.2  \\\n",
       "0          yes          yes          yes          yes           no   \n",
       "1          yes           no          yes          yes          yes   \n",
       "2          yes           no          yes          yes          yes   \n",
       "3          yes           no          yes          yes          yes   \n",
       "4          yes           no          yes          yes          yes   \n",
       "\n",
       "  criteria 7.3 criteria 7.4  \n",
       "0          yes           no  \n",
       "1           no           no  \n",
       "2          yes          yes  \n",
       "3          yes           no  \n",
       "4          yes           no  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply PAPER_ID_COL from other dataframe to the other dataframe (standarizing).\n",
    "df_llm = df_llm_raw.drop(columns=['no'])\n",
    "df_llm.columns = [\"paper_id\"] + SUB_CRITERIA\n",
    "df_llm[\"paper_id\"] = PAPER_IDS\n",
    "df_llm = df_llm.applymap(_canon_label)\n",
    "df_llm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6531941-43a7-4f9e-8961-f947f16ef5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Criteria x Papers (LLM / Ground Truth) with per-criterion accuracy ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>criteria 1.1</th>\n",
       "      <th>criteria 1.2</th>\n",
       "      <th>criteria 1.3</th>\n",
       "      <th>criteria 1.4</th>\n",
       "      <th>criteria 1.5</th>\n",
       "      <th>criteria 2.1</th>\n",
       "      <th>criteria 2.3</th>\n",
       "      <th>criteria 2.4</th>\n",
       "      <th>criteria 2.5</th>\n",
       "      <th>criteria 2.6</th>\n",
       "      <th>criteria 5.1</th>\n",
       "      <th>criteria 6.1</th>\n",
       "      <th>criteria 6.2</th>\n",
       "      <th>criteria 6.3</th>\n",
       "      <th>criteria 7.1</th>\n",
       "      <th>criteria 7.2</th>\n",
       "      <th>criteria 7.3</th>\n",
       "      <th>criteria 7.4</th>\n",
       "      <th>accuracy_paper wise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allcott, h</td>\n",
       "      <td>no / yes</td>\n",
       "      <td>yes / no</td>\n",
       "      <td>no / yes</td>\n",
       "      <td>no / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>no / no</td>\n",
       "      <td>yes / no</td>\n",
       "      <td>no / no</td>\n",
       "      <td>13/18 (72.2%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ayres, i; raseman, s; shih, a</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / no</td>\n",
       "      <td>no / no</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>no / no</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>no / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / no</td>\n",
       "      <td>no / no</td>\n",
       "      <td>no / no</td>\n",
       "      <td>15/18 (83.3%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bager, s; mundaca, l</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>no / no</td>\n",
       "      <td>no / no</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>no / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / no</td>\n",
       "      <td>16/18 (88.9%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carroll, j; lyons, s; denny, e</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>no / no</td>\n",
       "      <td>no / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>no / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / no</td>\n",
       "      <td>yes / no</td>\n",
       "      <td>no / no</td>\n",
       "      <td>14/18 (77.8%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>houde, s; todd, a; sudarshan, a; flora, ja; ar...</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / no</td>\n",
       "      <td>no / no</td>\n",
       "      <td>no / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / no</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>no / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>no / no</td>\n",
       "      <td>14/18 (77.8%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>matsukawa, i.</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>no / no</td>\n",
       "      <td>no / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / no</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / no</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / no</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / yes</td>\n",
       "      <td>yes / no</td>\n",
       "      <td>no / yes</td>\n",
       "      <td>12/18 (66.7%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>accuracy_subcriteria_wise</td>\n",
       "      <td>5/6 (83.3%)</td>\n",
       "      <td>3/6 (50.0%)</td>\n",
       "      <td>3/6 (50.0%)</td>\n",
       "      <td>4/6 (66.7%)</td>\n",
       "      <td>6/6 (100.0%)</td>\n",
       "      <td>6/6 (100.0%)</td>\n",
       "      <td>6/6 (100.0%)</td>\n",
       "      <td>5/6 (83.3%)</td>\n",
       "      <td>6/6 (100.0%)</td>\n",
       "      <td>5/6 (83.3%)</td>\n",
       "      <td>5/6 (83.3%)</td>\n",
       "      <td>6/6 (100.0%)</td>\n",
       "      <td>2/6 (33.3%)</td>\n",
       "      <td>5/6 (83.3%)</td>\n",
       "      <td>6/6 (100.0%)</td>\n",
       "      <td>4/6 (66.7%)</td>\n",
       "      <td>3/6 (50.0%)</td>\n",
       "      <td>4/6 (66.7%)</td>\n",
       "      <td>overall: 0.778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            paper_id criteria 1.1  \\\n",
       "0                                         allcott, h     no / yes   \n",
       "1                      ayres, i; raseman, s; shih, a    yes / yes   \n",
       "2                               bager, s; mundaca, l    yes / yes   \n",
       "3                     carroll, j; lyons, s; denny, e    yes / yes   \n",
       "4  houde, s; todd, a; sudarshan, a; flora, ja; ar...    yes / yes   \n",
       "5                                      matsukawa, i.    yes / yes   \n",
       "6                          accuracy_subcriteria_wise  5/6 (83.3%)   \n",
       "\n",
       "  criteria 1.2 criteria 1.3 criteria 1.4  criteria 1.5  criteria 2.1  \\\n",
       "0     yes / no     no / yes     no / yes     yes / yes     yes / yes   \n",
       "1     yes / no      no / no    yes / yes     yes / yes     yes / yes   \n",
       "2      no / no      no / no    yes / yes     yes / yes     yes / yes   \n",
       "3      no / no     no / yes    yes / yes     yes / yes     yes / yes   \n",
       "4     yes / no      no / no     no / yes     yes / yes     yes / yes   \n",
       "5      no / no     no / yes    yes / yes     yes / yes     yes / yes   \n",
       "6  3/6 (50.0%)  3/6 (50.0%)  4/6 (66.7%)  6/6 (100.0%)  6/6 (100.0%)   \n",
       "\n",
       "   criteria 2.3 criteria 2.4  criteria 2.5 criteria 2.6 criteria 5.1  \\\n",
       "0     yes / yes    yes / yes     yes / yes    yes / yes    yes / yes   \n",
       "1     yes / yes      no / no     yes / yes    yes / yes    yes / yes   \n",
       "2     yes / yes    yes / yes     yes / yes    yes / yes    yes / yes   \n",
       "3     yes / yes    yes / yes     yes / yes    yes / yes    yes / yes   \n",
       "4     yes / yes    yes / yes     yes / yes    yes / yes     yes / no   \n",
       "5     yes / yes     yes / no     yes / yes     yes / no    yes / yes   \n",
       "6  6/6 (100.0%)  5/6 (83.3%)  6/6 (100.0%)  5/6 (83.3%)  5/6 (83.3%)   \n",
       "\n",
       "   criteria 6.1 criteria 6.2 criteria 6.3  criteria 7.1 criteria 7.2  \\\n",
       "0     yes / yes    yes / yes    yes / yes     yes / yes      no / no   \n",
       "1     yes / yes     no / yes    yes / yes     yes / yes     yes / no   \n",
       "2     yes / yes     no / yes    yes / yes     yes / yes    yes / yes   \n",
       "3     yes / yes     no / yes    yes / yes     yes / yes     yes / no   \n",
       "4     yes / yes     no / yes    yes / yes     yes / yes    yes / yes   \n",
       "5     yes / yes    yes / yes     yes / no     yes / yes    yes / yes   \n",
       "6  6/6 (100.0%)  2/6 (33.3%)  5/6 (83.3%)  6/6 (100.0%)  4/6 (66.7%)   \n",
       "\n",
       "  criteria 7.3 criteria 7.4 accuracy_paper wise  \n",
       "0     yes / no      no / no       13/18 (72.2%)  \n",
       "1      no / no      no / no       15/18 (83.3%)  \n",
       "2    yes / yes     yes / no       16/18 (88.9%)  \n",
       "3     yes / no      no / no       14/18 (77.8%)  \n",
       "4    yes / yes      no / no       14/18 (77.8%)  \n",
       "5     yes / no     no / yes       12/18 (66.7%)  \n",
       "6  3/6 (50.0%)  4/6 (66.7%)      overall: 0.778  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = load_by_position(df_llm, PAPER_IDS, SUB_CRITERIA, PAPER_ID_COL)\n",
    "gt  = load_by_position(df_gt,  PAPER_IDS, SUB_CRITERIA, PAPER_ID_COL)\n",
    "\n",
    "# =========================\n",
    "# Build and display comparison\n",
    "# =========================\n",
    "comparison, acc = build_comparison(llm, gt, PAPER_IDS, SUB_CRITERIA, DISPLAY_SEPARATOR)\n",
    "\n",
    "# Add accuracy column per-criterion (row)\n",
    "# Definition: fraction of papers where LLM == GT for that criterion.\n",
    "# Denominator uses papers with non-empty ground-truth for that criterion.\n",
    "acc_values = []\n",
    "for crit in SUB_CRITERIA:\n",
    "    preds = llm.loc[PAPER_IDS, crit]\n",
    "    truths = gt.loc[PAPER_IDS, crit]\n",
    "    mask = truths.astype(str).str.len() > 0  # count only where GT present\n",
    "    total = int(mask.sum())\n",
    "    matches = int((preds[mask] == truths[mask]).sum()) if total > 0 else 0\n",
    "    acc_pct = (matches / total * 100.0) if total > 0 else None\n",
    "    formatted = f\"{matches}/{total} ({acc_pct:.1f}%)\" if total > 0 else \"n/a\"\n",
    "    acc_values.append(formatted)\n",
    "    \n",
    "comparison[\"accuracy_subcriteria_wise\"] = acc_values\n",
    "    \n",
    "# Add paper-wise accuracy at the bottom row (per column / paper)\n",
    "# Definition: fraction of criteria where LLM == GT for that paper\n",
    "acc_bottom = {}\n",
    "for p in PAPER_IDS:\n",
    "    preds = llm.loc[p, SUB_CRITERIA]\n",
    "    truths = gt.loc[p, SUB_CRITERIA]\n",
    "    total = len(SUB_CRITERIA)\n",
    "    matches = int((preds.values == truths.values).sum())\n",
    "    acc_pct = matches / total * 100.0\n",
    "    acc_bottom[p] = f\"{matches}/{total} ({acc_pct:.1f}%)\"\n",
    "\n",
    "# Append as the last row\n",
    "comparison.loc[\"accuracy_paper wise\"] = pd.Series(acc_bottom)\n",
    "\n",
    "direct_comparison_df = comparison.T\n",
    "direct_comparison_df.iat[-1,-1] = f\"overall: {acc}\"\n",
    "\n",
    "direct_comparison_df = direct_comparison_df.reset_index().rename(columns={\"index\": PAPER_ID_COL})\n",
    "\n",
    "print(\"=== Criteria x Papers (LLM / Ground Truth) with per-criterion accuracy ===\")\n",
    "display(direct_comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa9b9cc-b952-4653-89bb-c3795c4c0761",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Per-Criteria Wise Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "094e7450-a311-46c1-87ee-8fafe1683762",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def compute_per_paper_metrics_table(df_ref, df_res, filename):\n",
    "    df_ref_lower = df_ref.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "    df_res_lower = df_res.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "\n",
    "    criteria_cols = [col for col in df_ref.columns if col not in ['paper_id']]\n",
    "\n",
    "    # set positive as high.\n",
    "    positive = \"yes\"\n",
    "    negative = \"no\"\n",
    "\n",
    "    records = []\n",
    "    for col in criteria_cols:\n",
    "        for i, (ref_val, res_val) in enumerate(zip(df_ref_lower[col], df_res_lower[col])):\n",
    "            case_id = df_ref.loc[i, \"paper_id\"]\n",
    "\n",
    "            if ref_val == positive:\n",
    "                if res_val == positive:\n",
    "                    classification = \"TP\"\n",
    "                elif res_val == negative:\n",
    "                    classification = \"FN\"\n",
    "                else:\n",
    "                    classification = \"Unclear\"\n",
    "            elif ref_val == negative:\n",
    "                if res_val == positive:\n",
    "                    classification = \"FP\"\n",
    "                elif res_val == negative:\n",
    "                    classification = \"TN\"\n",
    "                else:\n",
    "                    classification = \"Unclear\"\n",
    "            else:\n",
    "                classification = \"Unclear\"\n",
    "\n",
    "            records.append({\n",
    "                \"ID\": case_id,\n",
    "                \"Criterion\": col,\n",
    "                \"Reference\": ref_val,\n",
    "                \"Prediction\": res_val,\n",
    "                \"Classification\": classification\n",
    "            })\n",
    "\n",
    "    comparison_df = pd.DataFrame(records)\n",
    "\n",
    "    study_stats = defaultdict(lambda: {\"TP\": 0, \"TN\": 0, \"FP\": 0, \"FN\": 0})\n",
    "\n",
    "    for _, row in comparison_df.iterrows():\n",
    "        study_id = row[\"ID\"]\n",
    "        cls = row[\"Classification\"]\n",
    "        if cls in study_stats[study_id]:\n",
    "            study_stats[study_id][cls] += 1\n",
    "\n",
    "    study_metrics = []\n",
    "\n",
    "    for study_id, counts in study_stats.items():\n",
    "        TP = counts[\"TP\"]\n",
    "        TN = counts[\"TN\"]\n",
    "        FP = counts[\"FP\"]\n",
    "        FN = counts[\"FN\"]\n",
    "        total = TP + TN + FP + FN\n",
    "\n",
    "        accuracy = (TP + TN) / total if total > 0 else 0\n",
    "        sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        f1_score = 2 * (precision * sensitivity) / (precision + sensitivity) if (precision + sensitivity) > 0 else 0\n",
    "\n",
    "        study_metrics.append({\n",
    "            \"ID\": study_id,\n",
    "            \"TP\": TP,\n",
    "            \"TN\": TN,\n",
    "            \"FP\": FP,\n",
    "            \"FN\": FN,\n",
    "            \"Correct assessment rate\": round(accuracy, 4),\n",
    "            \"Sensitivity\": round(sensitivity, 4),\n",
    "            \"Specificity\": round(specificity, 4),\n",
    "            \"Precision\": round(precision, 4),\n",
    "            \"F-score\": round(f1_score, 4),\n",
    "        })\n",
    "\n",
    "    study_metrics_df = pd.DataFrame(study_metrics)\n",
    "    return study_metrics_df\n",
    "    \n",
    "def compute_per_subcriteria_metrics_table(df_ref, df_res1):\n",
    "    df_ref = df_ref.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "    df_res1 = df_res1.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "\n",
    "    criteria_cols = [col for col in df_ref.columns if col not in ['paper_id']]\n",
    "    positive = \"yes\"\n",
    "    negative = \"no\"\n",
    "\n",
    "    def classify_entries(df_result):\n",
    "        records = []\n",
    "        for col in criteria_cols:\n",
    "            for i, (ref_val, res_val) in enumerate(zip(df_ref[col], df_result[col])):\n",
    "                #case_id = df_ref.loc[i, \"paper_id\"]\n",
    "                case_id = df_ref.iloc[i, df_ref.columns.get_loc(\"paper_id\")]\n",
    "\n",
    "                if ref_val == positive:\n",
    "                    if res_val == positive:\n",
    "                        cls = \"TP\"\n",
    "                    elif res_val == negative:\n",
    "                        cls = \"FN\"\n",
    "                    else:\n",
    "                        cls = \"Unclear\"\n",
    "                elif ref_val == negative:\n",
    "                    if res_val == positive:\n",
    "                        cls = \"FP\"\n",
    "                    elif res_val == negative:\n",
    "                        cls = \"TN\"\n",
    "                    else:\n",
    "                        cls = \"Unclear\"\n",
    "                else:\n",
    "                    cls = \"Unclear\"\n",
    "\n",
    "                records.append({\n",
    "                    \"ID\": case_id,\n",
    "                    \"Criterion\": col,\n",
    "                    \"Reference\": ref_val,\n",
    "                    \"Prediction\": res_val,\n",
    "                    \"Classification\": cls\n",
    "                })\n",
    "        return pd.DataFrame(records)\n",
    "\n",
    "    comp_df1 = classify_entries(df_res1)\n",
    "\n",
    "    def compute_domain_metrics(comp_df):\n",
    "        domain_stats = defaultdict(lambda: {\"TP\": 0, \"TN\": 0, \"FP\": 0, \"FN\": 0})\n",
    "        for _, row in comp_df.iterrows():\n",
    "            domain = row[\"Criterion\"]\n",
    "            cls = row[\"Classification\"]\n",
    "            if cls in domain_stats[domain]:\n",
    "                domain_stats[domain][cls] += 1\n",
    "\n",
    "        domain_metrics = []\n",
    "        for domain, counts in domain_stats.items():\n",
    "            TP = counts[\"TP\"]\n",
    "            TN = counts[\"TN\"]\n",
    "            FP = counts[\"FP\"]\n",
    "            FN = counts[\"FN\"]\n",
    "            total = TP + TN + FP + FN\n",
    "\n",
    "            acc = (TP + TN) / total if total > 0 else 0\n",
    "            sens = TP / (TP + FN) if (TP + FN) > 0 else None\n",
    "            spec = TN / (TN + FP) if (TN + FP) > 0 else None\n",
    "            prec = TP / (TP + FP) if (TP + FP) > 0 else None\n",
    "            f1 = (\n",
    "                2 * (prec * sens) / (prec + sens)\n",
    "                if prec is not None and sens is not None and (prec + sens) > 0\n",
    "                else None\n",
    "            )\n",
    "\n",
    "            domain_metrics.append({\n",
    "                \"Domain\": domain,\n",
    "                \"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN,\n",
    "                \"Accuracy\": round(acc, 4),\n",
    "                \"Sensitivity\": round(sens, 4) if sens is not None else \"Not available\",\n",
    "                \"Specificity\": round(spec, 4) if spec is not None else \"Not available\",\n",
    "                \"Precision\": round(prec, 4) if prec is not None else \"Not available\",\n",
    "                \"F-score\": round(f1, 4) if f1 is not None else \"Not available\",\n",
    "            })\n",
    "        return pd.DataFrame(domain_metrics)\n",
    "\n",
    "    df1 = compute_domain_metrics(comp_df1)\n",
    "\n",
    "    avg_rows = []\n",
    "    for _, row in df1.iterrows():\n",
    "        avg_rows.append({\n",
    "            \"Domain\": row[\"Domain\"],\n",
    "            \"TP\": row[\"TP\"],\n",
    "            \"TN\": row[\"TN\"],\n",
    "            \"FP\": row[\"FP\"],\n",
    "            \"FN\": row[\"FN\"],\n",
    "            \"Correct assessment rate\": row[\"Accuracy\"],\n",
    "            \"Sensitivity\": row[\"Sensitivity\"],\n",
    "            \"Specificity\": row[\"Specificity\"],\n",
    "            \"Precision\": row[\"Precision\"],\n",
    "            \"F-score\": row[\"F-score\"]})\n",
    "\n",
    "    avg_df = pd.DataFrame(avg_rows)\n",
    "    return avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43ddee94-bf2a-47cc-8fc0-d0342237484b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Correct assessment rate</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allcott, h</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7222</td>\n",
       "      <td>0.7857</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8462</td>\n",
       "      <td>0.8148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ayres, i; raseman, s; shih, a</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.8462</td>\n",
       "      <td>0.8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bager, s; mundaca, l</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.9333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carroll, j; lyons, s; denny, e</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.8571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>houde, s; todd, a; sudarshan, a; flora, ja; ar...</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.8571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ID  TP  TN  FP  FN  \\\n",
       "0                                         allcott, h  11   2   2   3   \n",
       "1                      ayres, i; raseman, s; shih, a  11   4   2   1   \n",
       "2                               bager, s; mundaca, l  14   2   1   1   \n",
       "3                     carroll, j; lyons, s; denny, e  12   2   2   2   \n",
       "4  houde, s; todd, a; sudarshan, a; flora, ja; ar...  12   2   2   2   \n",
       "\n",
       "   Correct assessment rate  Sensitivity  Specificity  Precision  F-score  \n",
       "0                   0.7222       0.7857       0.5000     0.8462   0.8148  \n",
       "1                   0.8333       0.9167       0.6667     0.8462   0.8800  \n",
       "2                   0.8889       0.9333       0.6667     0.9333   0.9333  \n",
       "3                   0.7778       0.8571       0.5000     0.8571   0.8571  \n",
       "4                   0.7778       0.8571       0.5000     0.8571   0.8571  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_paper_metrics_df = compute_per_paper_metrics_table(df_gt, df_llm, \"result_test\")\n",
    "per_paper_metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd9fd262-2147-46ff-ad05-38d49ec4302c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Correct assessment rate</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>criteria 1.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>Not available</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>criteria 1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>Not available</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>criteria 1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>criteria 1.4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>Not available</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>criteria 1.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not available</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>criteria 2.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not available</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>criteria 2.3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not available</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>criteria 2.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>criteria 2.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not available</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>criteria 2.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.9091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>criteria 5.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.9091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>criteria 6.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not available</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>criteria 6.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>Not available</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>criteria 6.3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.9091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>criteria 7.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not available</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>criteria 7.2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>criteria 7.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>criteria 7.4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Domain  TP  TN  FP  FN  Correct assessment rate    Sensitivity  \\\n",
       "0   criteria 1.1   5   0   0   1                   0.8333         0.8333   \n",
       "1   criteria 1.2   0   3   3   0                   0.5000  Not available   \n",
       "2   criteria 1.3   0   3   0   3                   0.5000            0.0   \n",
       "3   criteria 1.4   4   0   0   2                   0.6667         0.6667   \n",
       "4   criteria 1.5   6   0   0   0                   1.0000            1.0   \n",
       "5   criteria 2.1   6   0   0   0                   1.0000            1.0   \n",
       "6   criteria 2.3   6   0   0   0                   1.0000            1.0   \n",
       "7   criteria 2.4   4   1   1   0                   0.8333            1.0   \n",
       "8   criteria 2.5   6   0   0   0                   1.0000            1.0   \n",
       "9   criteria 2.6   5   0   1   0                   0.8333            1.0   \n",
       "10  criteria 5.1   5   0   1   0                   0.8333            1.0   \n",
       "11  criteria 6.1   6   0   0   0                   1.0000            1.0   \n",
       "12  criteria 6.2   2   0   0   4                   0.3333         0.3333   \n",
       "13  criteria 6.3   5   0   1   0                   0.8333            1.0   \n",
       "14  criteria 7.1   6   0   0   0                   1.0000            1.0   \n",
       "15  criteria 7.2   3   1   2   0                   0.6667            1.0   \n",
       "16  criteria 7.3   2   1   3   0                   0.5000            1.0   \n",
       "17  criteria 7.4   0   4   1   1                   0.6667            0.0   \n",
       "\n",
       "      Specificity      Precision        F-score  \n",
       "0   Not available            1.0         0.9091  \n",
       "1             0.5            0.0  Not available  \n",
       "2             1.0  Not available  Not available  \n",
       "3   Not available            1.0            0.8  \n",
       "4   Not available            1.0            1.0  \n",
       "5   Not available            1.0            1.0  \n",
       "6   Not available            1.0            1.0  \n",
       "7             0.5            0.8         0.8889  \n",
       "8   Not available            1.0            1.0  \n",
       "9             0.0         0.8333         0.9091  \n",
       "10            0.0         0.8333         0.9091  \n",
       "11  Not available            1.0            1.0  \n",
       "12  Not available            1.0            0.5  \n",
       "13            0.0         0.8333         0.9091  \n",
       "14  Not available            1.0            1.0  \n",
       "15         0.3333            0.6           0.75  \n",
       "16           0.25            0.4         0.5714  \n",
       "17            0.8            0.0  Not available  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_subcriteria_metrics_df = compute_per_subcriteria_metrics_table(df_gt, df_llm)\n",
    "per_subcriteria_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad00bfc-aab2-4eb3-92de-f954a7c190d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Per-Criteria Risk-Level Calculation\n",
    "Unlike direct per-criteria calculation, this script is specific to the prompt and criteria structure that we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f1d0472-aa25-4250-832c-0b5113bbb913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Risk calculation\n",
    "# =========================\n",
    "\n",
    "import pandas as pd\n",
    "from typing import Callable, Dict, List, Tuple\n",
    "\n",
    "_RISK_TO_NUM = {\"low\": 0, \"med\": 1, \"high\": 2}\n",
    "_NUM_TO_RISK = {v: k for k, v in _RISK_TO_NUM.items()}\n",
    "\n",
    "\n",
    "def _yn(x) -> str:\n",
    "    \"\"\"Normalize to yes/no (datasets should already be formatted).\"\"\"\n",
    "    #if pd.isna(x): return \"no\"\n",
    "    s = str(x).strip().lower()\n",
    "    if s in {\"yes\", \"y\", \"true\", \"1\"}: return \"yes\"\n",
    "    if s in {\"no\", \"n\", \"false\", \"0\"}: return \"no\"\n",
    "    return \"yes\" if \"yes\" in s else \"no\"\n",
    "\n",
    "# =========================\n",
    "# Rules from flowcharts found in CEE handbook.\n",
    "# =========================\n",
    "\n",
    "RULES_CRIT_1: Dict[Tuple[str, str, str, str, str], str] = {\n",
    "    # All decisions starting with 1.1 = no is coded in the risk_from_flow_1()\n",
    "    ('yes', 'yes', 'yes', 'yes', 'yes'): 'low',\n",
    "    ('yes', 'yes', 'no', 'yes', 'yes'): 'low',\n",
    "    \n",
    "    ('yes', 'yes', 'yes', 'no', 'yes'): 'low',\n",
    "    ('yes', 'yes', 'no', 'no', 'yes'): 'low',\n",
    "    \n",
    "    ('yes', 'yes', 'yes', 'no', 'no'): 'med',\n",
    "    ('yes', 'yes', 'no', 'no', 'no'): 'med',\n",
    "    ('yes', 'yes', 'no', 'yes', 'no'): 'med',\n",
    "    \n",
    "    ('yes', 'no', 'yes', 'yes', 'yes'): 'low',\n",
    "    ('yes', 'no', 'yes', 'no', 'yes'): 'low',\n",
    "    ('yes', 'no', 'yes', 'no', 'no'): 'high',\n",
    "    \n",
    "    ('yes', 'no', 'no', 'no', 'no'): 'high',\n",
    "    ('yes', 'no', 'no', 'yes', 'no'): 'high',\n",
    "    ('yes', 'no', 'no', 'no', 'yes'): 'high',\n",
    "    ('yes', 'no', 'no', 'yes', 'yes'): 'high',\n",
    "}\n",
    "\n",
    "def risk_from_flow_1(row: pd.Series,\n",
    "                     cols: List[str] = [\"criteria 1.1\", \"criteria 1.2\", \"criteria 1.3\", \"criteria 1.4\", \"criteria 1.5\"],\n",
    "                     rules: Dict[Tuple[str, str, str, str, str], str] = RULES_CRIT_1,\n",
    "                     default: str = \"NA\") -> str:\n",
    "    if row['criteria 1.1'] == 'no':\n",
    "        return 'low'\n",
    "    else:\n",
    "        values = tuple(_yn(row[c]) for c in cols)\n",
    "        return rules.get(values, default)\n",
    "\n",
    "RULES_CRIT_2: Dict[Tuple[str, str, str, str, str], str] = {\n",
    "    ('yes', 'no', 'no', 'no', 'no'): 'low',\n",
    "    ('yes', 'no', 'yes', 'no', 'no'): 'low',\n",
    "    ('yes', 'no', 'no', 'yes', 'no'): 'low',\n",
    "    ('yes', 'no', 'no', 'no', 'yes'): 'low',\n",
    "    ('yes', 'no', 'yes', 'yes', 'no'): 'low',\n",
    "    ('yes', 'no', 'no', 'yes', 'yes'): 'low',\n",
    "    ('yes', 'no', 'yes', 'no', 'yes'): 'low',\n",
    "    ('yes', 'no', 'yes', 'yes', 'yes'): 'low',\n",
    "    \n",
    "    ('yes', 'yes', 'yes', 'no', 'no'): 'med',\n",
    "    ('yes', 'yes', 'yes', 'yes', 'no'): 'med',\n",
    "    ('yes', 'yes', 'yes', 'no', 'yes'): 'med',\n",
    "    ('yes', 'yes', 'yes', 'yes', 'yes'): 'med',\n",
    "    \n",
    "    ('yes', 'yes', 'no', 'no', 'no'): 'med',\n",
    "    ('yes', 'yes', 'no', 'no', 'yes'): 'med',\n",
    "    ('yes', 'yes', 'yes', 'no', 'yes'): 'med',\n",
    "    \n",
    "    ('yes', 'yes', 'no', 'yes', 'no'): 'high',\n",
    "    ('yes', 'yes', 'no', 'yes', 'yes'): 'med',\n",
    "    \n",
    "    ('no', 'no', 'yes', 'no', 'no'): 'med',\n",
    "    ('no', 'no', 'yes', 'yes', 'no'): 'med',\n",
    "    ('no', 'no', 'yes', 'no', 'yes'): 'med',\n",
    "    ('no', 'no', 'yes', 'yes', 'yes'): 'med',\n",
    "    \n",
    "    ('no', 'no', 'no', 'no', 'no'): 'med',\n",
    "    ('no', 'no', 'no', 'no', 'yes'): 'med',\n",
    "    \n",
    "    ('no', 'no', 'no', 'yes', 'no'): 'high',\n",
    "    ('no', 'no', 'no', 'yes', 'yes'): 'med',\n",
    "    \n",
    "    \n",
    "    ('no', 'yes', 'yes', 'no', 'no'): 'med',\n",
    "    ('no', 'yes', 'yes', 'yes', 'no'): 'med',\n",
    "    ('no', 'yes', 'yes', 'no', 'yes'): 'med',\n",
    "    ('no', 'yes', 'yes', 'yes', 'yes'): 'med',\n",
    "    \n",
    "    ('no', 'yes', 'no', 'no', 'no'): 'med',\n",
    "    ('no', 'yes', 'no', 'no', 'yes'): 'med',\n",
    "    \n",
    "    ('no', 'yes', 'no', 'yes', 'no'): 'high',\n",
    "    ('no', 'yes', 'no', 'yes', 'yes'): 'med',\n",
    "}\n",
    "\n",
    "def risk_from_flow_2(row: pd.Series,\n",
    "                     cols: List[str] = [\"criteria 2.1\", \"criteria 2.3\", \"criteria 2.4\", \"criteria 2.5\", \"criteria 2.6\"],\n",
    "                     rules: Dict[Tuple[str, str, str, str, str], str] = RULES_CRIT_2,\n",
    "                     default: str = \"NA\") -> str:\n",
    "    values = tuple(_yn(row[c]) for c in cols)\n",
    "    return rules.get(values, default)\n",
    "\n",
    "RULES_CRIT_5: Dict[Tuple[str], str] = {} # stub.\n",
    "\n",
    "def risk_from_flow_5(row: pd.Series,\n",
    "                     cols: List[str] = [\"criteria 5.1\"],\n",
    "                     rules: Dict[Tuple[str], str] = RULES_CRIT_5,\n",
    "                     default: str = \"NA\") -> str:\n",
    "    \n",
    "    if row['criteria 5.1'] == 'no':\n",
    "        return 'low'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "RULES_CRIT_6: Dict[Tuple[str, str, str], str] = {\n",
    "    (\"no\", \"no\", \"no\"): \"low\",\n",
    "    (\"no\", \"no\", \"yes\"):  \"med\",\n",
    "    (\"no\", \"yes\", \"no\"): \"med\",\n",
    "    (\"no\", \"yes\", \"yes\"): \"high\",\n",
    "    (\"yes\", \"no\",  \"no\"):  \"med\",\n",
    "    (\"yes\",  \"no\", \"yes\"): \"high\",\n",
    "    (\"yes\",  \"yes\", \"no\"):  \"high\",\n",
    "    (\"yes\",  \"yes\",  \"yes\"): \"high\",\n",
    "}\n",
    "\n",
    "def risk_from_flow_6(row: pd.Series,\n",
    "                     cols: List[str] = [\"criteria 6.1\", \"criteria 6.2\", \"criteria 6.3\"],\n",
    "                     rules: Dict[Tuple[str, str, str], str] = RULES_CRIT_6,\n",
    "                     default: str = \"NA\") -> str:\n",
    "    values = tuple(_yn(row[c]) for c in cols)\n",
    "    return rules.get(values, default)\n",
    "\n",
    "RULES_CRIT_7: Dict[Tuple[str, str, str, str], str] = {\n",
    "    ('no', 'no', 'no', 'no'): 'low',\n",
    "    ('no', 'no', 'no', 'yes'): 'low', #\n",
    "    ('no', 'no', 'yes', 'no'): 'high',\n",
    "    ('no', 'no', 'yes', 'yes'): 'high', #\n",
    "    ('no', 'yes', 'no', 'no'): 'high',\n",
    "    ('no', 'yes', 'yes', 'no'): 'high',\n",
    "    ('no', 'yes', 'no', 'yes'): 'high',\n",
    "    ('no', 'yes', 'yes', 'yes'): 'high', #\n",
    "    ('yes', 'no', 'no', 'no'): 'med',\n",
    "    ('yes', 'no', 'no', 'yes'): 'med', #\n",
    "    ('yes', 'no', 'yes', 'no'): 'high',\n",
    "    ('yes', 'no', 'yes', 'yes'): 'high', #\n",
    "    ('yes', 'yes', 'no', 'no'): 'high',\n",
    "    ('yes', 'yes', 'yes', 'no'): 'high',\n",
    "    ('yes', 'yes', 'no', 'yes'): 'high',\n",
    "    ('yes', 'yes', 'yes', 'yes'): 'high',\n",
    "}\n",
    "\n",
    "def risk_from_flow_7(row: pd.Series,\n",
    "                     cols: List[str] = [\"criteria 7.1\", \"criteria 7.2\", \"criteria 7.3\", \"criteria 7.4\"],\n",
    "                     rules: Dict[Tuple[str, str, str, str], str] = RULES_CRIT_7,\n",
    "                     default: str = \"NA\") -> str:\n",
    "    values = tuple(_yn(row[c]) for c in cols)\n",
    "    return rules.get(values, default)\n",
    "\n",
    "# =========================\n",
    "# Define top-level criteria.\n",
    "# Maps criterion name -> function(row)-> 'low'/'med'/'high'.\n",
    "# =========================\n",
    "\n",
    "CRITERION_FUNCS: Dict[str, Callable[[pd.Series], str]] = {\n",
    "    \"criterion_1\": risk_from_flow_1,\n",
    "    \"criterion_2\": risk_from_flow_2,\n",
    "    \"criterion_5\": risk_from_flow_5,\n",
    "    \"criterion_6\": risk_from_flow_6,\n",
    "    \"criterion_7\": risk_from_flow_7,\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# Main APIs\n",
    "# =========================\n",
    "def calculate_risk_paper(row: pd.Series,\n",
    "                         paper_title_col: str = PAPER_ID_COL,\n",
    "                         crit_funcs: Dict[str, Callable[[pd.Series], str]] = CRITERION_FUNCS\n",
    "                         ) -> Tuple[str, Dict[str, str], str]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      paper_title,\n",
    "      risk_level_per_criteria: dict {criterion_name: 'low'|'med'|'high'},\n",
    "    \"\"\"\n",
    "    per_crit = {crit_name: fn(row) for crit_name, fn in crit_funcs.items()}\n",
    "    return str(row[paper_title_col]), per_crit\n",
    "\n",
    "def calculate_risk_all_papers(df: pd.DataFrame,\n",
    "                              paper_title_col: str = PAPER_ID_COL,\n",
    "                              crit_funcs: Dict[str, Callable[[pd.Series], str]] = CRITERION_FUNCS\n",
    "                              ) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Applies calculate_risk_paper() over all rows.\n",
    "    Returns:\n",
    "      summary_df: columns ['paper_title','risk_level']\n",
    "      details_df: columns ['paper_title', <one per criterion>, 'overall']\n",
    "    \"\"\"\n",
    "    titles: List[str] = []\n",
    "    percrit_rows: List[Dict[str, str]] = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        title, percrit = calculate_risk_paper(row, paper_title_col, crit_funcs)\n",
    "        titles.append(title)\n",
    "        percrit_rows.append(percrit)\n",
    "\n",
    "    details_df = pd.DataFrame(percrit_rows)\n",
    "    details_df.insert(0, PAPER_ID_COL, titles)\n",
    "\n",
    "    return details_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c04a575-1208-450c-b8b8-d64aa54edc2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>criterion_1</th>\n",
       "      <th>criterion_2</th>\n",
       "      <th>criterion_5</th>\n",
       "      <th>criterion_6</th>\n",
       "      <th>criterion_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allcott, h</td>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ayres, i; raseman, s; shih, a</td>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bager, s; mundaca, l</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carroll, j; lyons, s; denny, e</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>houde, s; todd, a; sudarshan, a; flora, ja; ar...</td>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>matsukawa, i.</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            paper_id criterion_1 criterion_2  \\\n",
       "0                                         allcott, h         low         med   \n",
       "1                      ayres, i; raseman, s; shih, a         low         med   \n",
       "2                               bager, s; mundaca, l        high         med   \n",
       "3                     carroll, j; lyons, s; denny, e        high         med   \n",
       "4  houde, s; todd, a; sudarshan, a; flora, ja; ar...         low         med   \n",
       "5                                      matsukawa, i.        high         med   \n",
       "\n",
       "  criterion_5 criterion_6 criterion_7  \n",
       "0        high        high        high  \n",
       "1        high        high        high  \n",
       "2        high        high        high  \n",
       "3        high        high        high  \n",
       "4        high        high        high  \n",
       "5        high        high        high  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>criterion_1</th>\n",
       "      <th>criterion_2</th>\n",
       "      <th>criterion_5</th>\n",
       "      <th>criterion_6</th>\n",
       "      <th>criterion_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allcott, h</td>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ayres, i; raseman, s; shih, a</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bager, s; mundaca, l</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carroll, j; lyons, s; denny, e</td>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>houde, s; todd, a; sudarshan, a; flora, ja; ar...</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>matsukawa, i.</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            paper_id criterion_1 criterion_2  \\\n",
       "0                                         allcott, h         low         med   \n",
       "1                      ayres, i; raseman, s; shih, a        high         med   \n",
       "2                               bager, s; mundaca, l        high         med   \n",
       "3                     carroll, j; lyons, s; denny, e         low         med   \n",
       "4  houde, s; todd, a; sudarshan, a; flora, ja; ar...        high         med   \n",
       "5                                      matsukawa, i.         low        high   \n",
       "\n",
       "  criterion_5 criterion_6 criterion_7  \n",
       "0        high        high         med  \n",
       "1        high        high         med  \n",
       "2        high        high        high  \n",
       "3        high        high         med  \n",
       "4         low        high        high  \n",
       "5        high        high        high  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_risk_df = calculate_risk_all_papers(df_llm, paper_title_col=PAPER_ID_COL, crit_funcs=CRITERION_FUNCS)\n",
    "display(llm_risk_df)\n",
    "\n",
    "gt_risk_df = calculate_risk_all_papers(df_gt, paper_title_col=PAPER_ID_COL, crit_funcs=CRITERION_FUNCS)\n",
    "display(gt_risk_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d6fe25-6b24-4f74-8acc-a7a0d01474a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Risk Level Per Criteria Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd1e595f-71f1-41ad-877a-9720684a003c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_rob_details(llm_df: pd.DataFrame, gt_df: pd.DataFrame,\n",
    "                        titles: list, criteria_order: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compare LLM vs Ground Truth RoB details and return a clean DataFrame.\n",
    "\n",
    "    The DataFrame contains:\n",
    "      - All papers with title, criteria columns, overall, and row_accuracy.\n",
    "      - A final row for column_accuracy.\n",
    "      - The overall accuracy (based only on overall column) displayed in the last bottom right cell.\n",
    "\n",
    "    Assumptions:\n",
    "      - Titles and criteria_order are authoritative and overwrite dataset order/names.\n",
    "      - Each criterion cell is formatted as \"llm / gt\".\n",
    "    \"\"\"\n",
    "\n",
    "    title_col = PAPER_ID_COL\n",
    "\n",
    "    def _select_and_standardize(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        candidate = [c for c in df.columns if c not in (title_col)]\n",
    "        k = len(criteria_order)\n",
    "        crit_cols = candidate[:k]\n",
    "        view = df[[title_col] + crit_cols]\n",
    "        rename_map = {old: new for old, new in zip(crit_cols, criteria_order)}\n",
    "        view = view.rename(columns=rename_map)\n",
    "        return view\n",
    "\n",
    "    llm_idx = llm_df.set_index(title_col)\n",
    "    gt_idx  = gt_df.set_index(title_col)\n",
    "\n",
    "    llm_sel_raw = llm_idx.loc[titles].reset_index()\n",
    "    gt_sel_raw  = gt_idx.loc[titles].reset_index()\n",
    "\n",
    "    llm_sel = _select_and_standardize(llm_sel_raw)\n",
    "    gt_sel  = _select_and_standardize(gt_sel_raw)\n",
    "\n",
    "    def _norm(df: pd.DataFrame, cols: list) -> pd.DataFrame:\n",
    "        out = df.copy()\n",
    "        for c in cols:\n",
    "            out[c] = out[c].astype(str).str.strip().str.lower()\n",
    "        return out\n",
    "\n",
    "    llm_norm = _norm(llm_sel, criteria_order)\n",
    "    gt_norm  = _norm(gt_sel,  criteria_order)\n",
    "\n",
    "    # Build comparison table\n",
    "    comp = pd.DataFrame({\"title\": titles})\n",
    "    for c in criteria_order:\n",
    "        comp[c] = llm_norm[c] + \" / \" + gt_norm[c]\n",
    "\n",
    "    # Accuracy calculations\n",
    "    matches = pd.DataFrame({c: (llm_norm[c] == gt_norm[c]) for c in criteria_order})\n",
    "\n",
    "    # Row-wise accuracy (per paper across criteria)\n",
    "    row_acc = matches.mean(axis=1)\n",
    "    \n",
    "    # row-wise fraction\n",
    "    row_acc_str = []\n",
    "    total = len(criteria_order)\n",
    "    for i, c in enumerate(titles):\n",
    "        match = matches.sum(axis=1)[i]\n",
    "        row_acc_str.append(f\"{match}/{total} ({row_acc[i].round(3)})\")\n",
    "    \n",
    "    comp[\"row_accuracy\"] = row_acc_str\n",
    "\n",
    "    # Column-wise accuracy (per criterion across all papers)\n",
    "    col_acc = matches.mean(axis=0).round(3) # a list.\n",
    "    \n",
    "    # Column-wise fraction\n",
    "    col_acc_str = []\n",
    "    correct_answer = 0\n",
    "    total = len(titles)\n",
    "    for i, c in enumerate(criteria_order):\n",
    "        match = matches.sum(axis=0)[i]\n",
    "        col_acc_str.append(f\"{match}/{total} ({col_acc[i]})\")\n",
    "        correct_answer += match\n",
    "\n",
    "    # Add column_accuracy as the last row\n",
    "    acc_row = {\"title\": \"column_accuracy\"}\n",
    "    for i, c in enumerate(criteria_order):\n",
    "        acc_row[c] = col_acc_str[i]\n",
    "    acc_row[\"row_accuracy\"] = \"\"\n",
    "\n",
    "    comp = pd.concat([comp, pd.DataFrame([acc_row])], ignore_index=True)\n",
    "    \n",
    "    # Overall accuracy based only on overall column\n",
    "    acc = (correct_answer / (len(titles)*len(criteria_order))).round(3)\n",
    "    \n",
    "    # Put overall accuracy at the bottom right cell.\n",
    "    comp.iat[-1,-1] = f\"overall: {acc}\"\n",
    "\n",
    "    return comp, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b950dbbc-d505-4d56-913e-0ffcaf91e229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['criterion_1', 'criterion_2', 'criterion_5', 'criterion_6', 'criterion_7']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get column names from gt_risk_df.\n",
    "excluded = [PAPER_ID_COL]\n",
    "RISK_CRITERIA = [str(col) for col in gt_risk_df.columns if col not in excluded]\n",
    "RISK_CRITERIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b205e6c7-e62f-4d44-b591-cb35cabc296a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>criterion_1</th>\n",
       "      <th>criterion_2</th>\n",
       "      <th>criterion_5</th>\n",
       "      <th>criterion_6</th>\n",
       "      <th>criterion_7</th>\n",
       "      <th>row_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allcott, h</td>\n",
       "      <td>low / low</td>\n",
       "      <td>med / med</td>\n",
       "      <td>high / high</td>\n",
       "      <td>high / high</td>\n",
       "      <td>high / med</td>\n",
       "      <td>4/5 (0.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ayres, i; raseman, s; shih, a</td>\n",
       "      <td>low / high</td>\n",
       "      <td>med / med</td>\n",
       "      <td>high / high</td>\n",
       "      <td>high / high</td>\n",
       "      <td>high / med</td>\n",
       "      <td>3/5 (0.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bager, s; mundaca, l</td>\n",
       "      <td>high / high</td>\n",
       "      <td>med / med</td>\n",
       "      <td>high / high</td>\n",
       "      <td>high / high</td>\n",
       "      <td>high / high</td>\n",
       "      <td>5/5 (1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carroll, j; lyons, s; denny, e</td>\n",
       "      <td>high / low</td>\n",
       "      <td>med / med</td>\n",
       "      <td>high / high</td>\n",
       "      <td>high / high</td>\n",
       "      <td>high / med</td>\n",
       "      <td>3/5 (0.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>houde, s; todd, a; sudarshan, a; flora, ja; ar...</td>\n",
       "      <td>low / high</td>\n",
       "      <td>med / med</td>\n",
       "      <td>high / low</td>\n",
       "      <td>high / high</td>\n",
       "      <td>high / high</td>\n",
       "      <td>3/5 (0.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>matsukawa, i.</td>\n",
       "      <td>high / low</td>\n",
       "      <td>med / high</td>\n",
       "      <td>high / high</td>\n",
       "      <td>high / high</td>\n",
       "      <td>high / high</td>\n",
       "      <td>3/5 (0.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>column_accuracy</td>\n",
       "      <td>2/6 (0.333)</td>\n",
       "      <td>5/6 (0.833)</td>\n",
       "      <td>5/6 (0.833)</td>\n",
       "      <td>6/6 (1.0)</td>\n",
       "      <td>3/6 (0.5)</td>\n",
       "      <td>overall: 0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  criterion_1  \\\n",
       "0                                         allcott, h    low / low   \n",
       "1                      ayres, i; raseman, s; shih, a   low / high   \n",
       "2                               bager, s; mundaca, l  high / high   \n",
       "3                     carroll, j; lyons, s; denny, e   high / low   \n",
       "4  houde, s; todd, a; sudarshan, a; flora, ja; ar...   low / high   \n",
       "5                                      matsukawa, i.   high / low   \n",
       "6                                    column_accuracy  2/6 (0.333)   \n",
       "\n",
       "   criterion_2  criterion_5  criterion_6  criterion_7  row_accuracy  \n",
       "0    med / med  high / high  high / high   high / med     4/5 (0.8)  \n",
       "1    med / med  high / high  high / high   high / med     3/5 (0.6)  \n",
       "2    med / med  high / high  high / high  high / high     5/5 (1.0)  \n",
       "3    med / med  high / high  high / high   high / med     3/5 (0.6)  \n",
       "4    med / med   high / low  high / high  high / high     3/5 (0.6)  \n",
       "5   med / high  high / high  high / high  high / high     3/5 (0.6)  \n",
       "6  5/6 (0.833)  5/6 (0.833)    6/6 (1.0)    3/6 (0.5)  overall: 0.7  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "# Generates risk-level comparisons per criteria.\n",
    "cmp_risk_df, acc = compare_rob_details(llm_risk_df, gt_risk_df, PAPER_IDS, RISK_CRITERIA)\n",
    "\n",
    "display(cmp_risk_df)\n",
    "print(f\"Overall accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0381d3-5df6-4f46-ac66-5944638eb0f0",
   "metadata": {},
   "source": [
    "# Per Criteria Risk-Level Confusion Matrix + Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b26ac97-062b-4ec7-a7fd-f62de970e7ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "def evaluate_criteria(df_gt, df_llm, labels=[\"low\", \"med\", \"high\"]):\n",
    "    # Select only criteria columns.\n",
    "    criteria_cols = [c for c in df_gt.columns if c.startswith(\"criterion\")]\n",
    "    \n",
    "    # Flatten into 1-D arrays.\n",
    "    y_true = df_gt[criteria_cols].values.ravel()\n",
    "    y_pred = df_llm[criteria_cols].values.ravel()\n",
    "    \n",
    "    # Confusion matrix.\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_df = pd.DataFrame(cm,\n",
    "                         index=[f\"Actual {l}\" for l in labels],\n",
    "                         columns=[f\"Pred {l}\" for l in labels])\n",
    "    \n",
    "    # Per-class (per risk-level) metrics.\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, labels=labels, zero_division=0\n",
    "    )\n",
    "    \n",
    "    metrics_df = pd.DataFrame({\n",
    "        \"Class\": labels,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-score\": f1,\n",
    "        \"Support\": support\n",
    "    })\n",
    "    \n",
    "    # Overall accuracy.\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    return cm_df, metrics_df, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a618c560-620e-4f9c-96f8-2305a630ae63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "             Pred low  Pred med  Pred high\n",
      "Actual low          1         0          3\n",
      "Actual med          0         5          3\n",
      "Actual high         2         1         15 \n",
      "\n",
      "              Class  Precision    Recall  F1-score Support  Accuracy\n",
      "0               low   0.333333  0.250000  0.285714       4       NaN\n",
      "1               med   0.833333  0.625000  0.714286       8       NaN\n",
      "2              high   0.714286  0.833333  0.769231      18       NaN\n",
      "3  Overall Accuracy        NaN       NaN       NaN    None       0.7\n"
     ]
    }
   ],
   "source": [
    "cm_df, metrics_df, acc = evaluate_criteria(gt_risk_df, llm_risk_df)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_df, \"\\n\")\n",
    "\n",
    "acc_df = pd.DataFrame([{\n",
    "    \"Class\": \"Overall Accuracy\",\n",
    "    \"Precision\": None,\n",
    "    \"Recall\": None,\n",
    "    \"F1-score\": None,\n",
    "    \"Support\": None,\n",
    "    \"Accuracy\": acc\n",
    "}])\n",
    "\n",
    "# Concatenate metrics with the accuracy row\n",
    "combined_metrics_df = pd.concat([metrics_df, acc_df], ignore_index=True)\n",
    "print(combined_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40024b69-d902-4172-a219-ee9e5d9cde71",
   "metadata": {},
   "source": [
    "## Save all results into an excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd093595-059a-4a87-8879-a87c8c0a8b10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "formatted_time = time.strftime(\"%Y-%m-%d_%H:%M:%S\", time.localtime())\n",
    "\n",
    "dfs = {\n",
    "    'formatted_llm_results' : df_llm,\n",
    "    'formatted_gt' : df_gt,\n",
    "    'direct_comp' : direct_comparison_df,\n",
    "    'per_paper_metrics' : per_paper_metrics_df,\n",
    "    'per_criteria_metrics' : per_subcriteria_metrics_df,\n",
    "    'risk_llm' : llm_risk_df,\n",
    "    'risk_gt' : gt_risk_df,\n",
    "    'risk_comp' : cmp_risk_df,\n",
    "    'risk_confusion_matrix' : cm_df,\n",
    "    'risk_metrics' : combined_metrics_df\n",
    "}\n",
    "\n",
    "with pd.ExcelWriter(f\"output/results_{formatted_time}.xlsx\", engine=\"openpyxl\") as writer:\n",
    "    for sheet_name, data in dfs.items():\n",
    "        data.to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87397dfc-7648-4dc5-9e96-7640cc3d824e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
